"""
BigQuery Analytics Module
Core analytics functions for artisan insights
"""

from google.cloud import bigquery
from google.oauth2 import service_account
from typing import Dict, List, Any, Optional
import os

# Global client variable
_client = None

def get_bigquery_client() -> Optional[bigquery.Client]:
    """
    Initialize BigQuery client lazily with proper error handling
    Returns None if credentials are not available
    """
    global _client
    
    if _client is not None:
        return _client
    
    try:
        credentials_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
        project_id = os.environ.get("GCLOUD_PROJECT")
        
        if not credentials_path or not os.path.exists(credentials_path):
            print(f"Warning: BigQuery credentials not found at {credentials_path}")
            return None
        
        if not project_id:
            print("Warning: GCLOUD_PROJECT not set in environment")
            return None
        
        credentials = service_account.Credentials.from_service_account_file(credentials_path)
        _client = bigquery.Client(credentials=credentials, project=project_id)
        
        print(f"‚úÖ BigQuery client initialized for project: {project_id}")
        return _client
        
    except Exception as e:
        print(f"‚ùå BigQuery client initialization failed: {e}")
        return None

def get_mock_data() -> Dict[str, Any]:
    """Return comprehensive mock data when BigQuery is unavailable"""
    return {
        "target_audience_data": {
            "target_audience": [
                "Women aged 25-34",
                "Metropolitan areas (Mumbai, Delhi, Bangalore)",
                "Festival shoppers and gift buyers",
                "Premium handicraft collectors"
            ],
            "detailed_demographics": []
        },
        "timing_data": {
            "best_timing": [
                "Post between 7-9 PM for maximum reach",
                "Thursdays and Fridays show 30% higher engagement",
                "2 weeks before festivals for promotional content",
                "Weekend mornings (10 AM - 12 PM) for product showcases"
            ],
            "detailed_timing": []
        },
        "price_data": {
            "price_bands": [
                {"range": "‚Çπ2000-5000", "percentage": 45},
                {"range": "‚Çπ5000-10000", "percentage": 35},
                {"range": "‚Çπ10000+", "percentage": 20}
            ]
        },
        "key_insights": [
            {"icon": "üìà", "text": "Your handwoven products got 40% more clicks than printed ones", "trend": "up"},
            {"icon": "üéâ", "text": "Festival-related keywords increased reach by 25%", "trend": "up"},
            {"icon": "‚≠ê", "text": "Products priced ‚Çπ2000-5000 have highest conversion rate", "trend": "neutral"},
            {"icon": "üåü", "text": "Traditional designs outperform modern styles by 35%", "trend": "up"}
        ],
        "recommended_channels": [
            {"name": "Instagram Reels", "reason": "High engagement for visual products and craft demonstrations"},
            {"name": "Pinterest Boards", "reason": "Strong discovery for traditional wear and home decor"},
            {"name": "WhatsApp Business", "reason": "Direct customer communication with 60% response rate"},
            {"name": "Facebook Marketplace", "reason": "Local buyers searching for authentic handmade items"}
        ]
    }

def get_target_audience(artisan_id: str) -> Dict[str, Any]:
    """Get target audience insights for an artisan"""
    
    client = get_bigquery_client()
    
    if not client:
        print(f"Using mock data for target_audience (artisan: {artisan_id})")
        return get_mock_data()["target_audience_data"]
    
    try:
        project_id = os.environ.get("GCLOUD_PROJECT")
        
        query = f"""
        WITH audience_data AS (
            SELECT 
                d.age_group,
                d.location_state,
                d.location_city,
                COUNT(DISTINCT i.user_id) as user_count,
                COUNTIF(i.action_type = 'click') as clicks,
                COUNTIF(i.action_type = 'inquiry') as inquiries,
                COUNTIF(i.action_type = 'purchase') as purchases
            FROM `{project_id}.artisan_analytics.user_interactions` i
            LEFT JOIN `{project_id}.artisan_analytics.user_demographics` d
                ON i.user_id = d.user_id
            WHERE i.artisan_id = @artisan_id
                AND i.timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)
            GROUP BY d.age_group, d.location_state, d.location_city
        )
        SELECT 
            age_group,
            location_state,
            location_city,
            user_count,
            clicks,
            inquiries,
            purchases,
            ROUND(clicks / NULLIF(user_count, 0) * 100, 2) as click_rate,
            ROUND(inquiries / NULLIF(clicks, 0) * 100, 2) as inquiry_rate
        FROM audience_data
        ORDER BY user_count DESC
        LIMIT 10
        """
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("artisan_id", "STRING", artisan_id)
            ]
        )
        
        results = client.query(query, job_config=job_config).result()
        
        # Process results
        top_demographics = []
        top_locations = set()
        top_age_groups = {}
        
        for row in results:
            top_demographics.append(dict(row))
            
            if row.location_city and row.location_state:
                top_locations.add(f"{row.location_city}, {row.location_state}")
            
            if row.age_group:
                top_age_groups[row.age_group] = top_age_groups.get(row.age_group, 0) + row.user_count
        
        # Format output
        target_audience = []
        
        # Top age group
        if top_age_groups:
            top_age = max(top_age_groups.items(), key=lambda x: x[1])
            target_audience.append(f"Primary age group: {top_age[0]}")
        
        # Top locations
        if top_locations:
            top_3_locations = list(top_locations)[:3]
            target_audience.append(f"Key cities: {', '.join(top_3_locations)}")
        
        # Behavior pattern
        total_clicks = sum(d.get('clicks', 0) for d in top_demographics)
        total_inquiries = sum(d.get('inquiries', 0) for d in top_demographics)
        
        if total_clicks > 0:
            inquiry_rate = (total_inquiries / total_clicks) * 100
            if inquiry_rate > 15:
                target_audience.append("High-intent shoppers (strong inquiry rate)")
            else:
                target_audience.append("Browsers (exploring options)")
        
        return {
            "target_audience": target_audience if target_audience else get_mock_data()["target_audience_data"]["target_audience"],
            "detailed_demographics": top_demographics[:5]
        }
        
    except Exception as e:
        print(f"Error in get_target_audience: {e}")
        return get_mock_data()["target_audience_data"]

def get_best_timing(artisan_id: str) -> Dict[str, Any]:
    """Get best posting times based on engagement"""
    
    client = get_bigquery_client()
    
    if not client:
        print(f"Using mock data for best_timing (artisan: {artisan_id})")
        return get_mock_data()["timing_data"]
    
    try:
        project_id = os.environ.get("GCLOUD_PROJECT")
        
        query = f"""
        WITH hourly_engagement AS (
            SELECT 
                EXTRACT(DAYOFWEEK FROM timestamp) as day_of_week,
                EXTRACT(HOUR FROM timestamp) as hour,
                COUNT(*) as interactions,
                COUNTIF(action_type = 'click') as clicks,
                COUNTIF(action_type = 'inquiry') as inquiries
            FROM `{project_id}.artisan_analytics.user_interactions`
            WHERE artisan_id = @artisan_id
                AND timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)
            GROUP BY day_of_week, hour
        ),
        ranked_times AS (
            SELECT 
                day_of_week,
                hour,
                interactions,
                clicks,
                inquiries,
                ROW_NUMBER() OVER (ORDER BY clicks DESC) as rank
            FROM hourly_engagement
        )
        SELECT 
            day_of_week,
            hour,
            interactions,
            clicks,
            inquiries
        FROM ranked_times
        WHERE rank <= 5
        ORDER BY clicks DESC
        """
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("artisan_id", "STRING", artisan_id)
            ]
        )
        
        results = client.query(query, job_config=job_config).result()
        
        # Map day numbers to names
        day_names = {1: 'Sunday', 2: 'Monday', 3: 'Tuesday', 4: 'Wednesday', 
                     5: 'Thursday', 6: 'Friday', 7: 'Saturday'}
        
        best_hours = []
        best_days = {}
        
        for row in results:
            day_name = day_names.get(row.day_of_week, 'Unknown')
            best_days[day_name] = best_days.get(day_name, 0) + row.clicks
            
            hour = row.hour
            time_period = "morning" if 6 <= hour < 12 else "afternoon" if 12 <= hour < 17 else "evening" if 17 <= hour < 21 else "night"
            best_hours.append({
                "day": day_name,
                "hour": hour,
                "period": time_period,
                "engagement": row.clicks
            })
        
        # Generate recommendations
        recommendations = []
        
        if best_hours:
            top_hour = best_hours[0]
            recommendations.append(
                f"Post between {top_hour['hour']}:00-{(top_hour['hour']+2)%24}:00 for maximum reach"
            )
        
        if best_days:
            sorted_days = sorted(best_days.items(), key=lambda x: x[1], reverse=True)[:2]
            day_str = ' and '.join([d[0] for d in sorted_days])
            recommendations.append(f"{day_str} show highest engagement")
        
        recommendations.append("2 weeks before festivals for promotional content")
        
        return {
            "best_timing": recommendations if recommendations else get_mock_data()["timing_data"]["best_timing"],
            "detailed_timing": best_hours
        }
        
    except Exception as e:
        print(f"Error in get_best_timing: {e}")
        return get_mock_data()["timing_data"]

def get_price_performance(artisan_id: str) -> Dict[str, Any]:
    """Analyze price band performance"""
    
    client = get_bigquery_client()
    
    if not client:
        print(f"Using mock data for price_performance (artisan: {artisan_id})")
        return get_mock_data()["price_data"]
    
    try:
        project_id = os.environ.get("GCLOUD_PROJECT")
        
        query = f"""
        WITH price_analysis AS (
            SELECT 
                CASE 
                    WHEN p.price < 500 THEN '‚Çπ0-500'
                    WHEN p.price < 1000 THEN '‚Çπ500-1000'
                    WHEN p.price < 2500 THEN '‚Çπ1000-2500'
                    WHEN p.price < 5000 THEN '‚Çπ2500-5000'
                    ELSE '‚Çπ5000+'
                END as price_band,
                COUNT(DISTINCT i.user_id) as unique_viewers,
                COUNTIF(i.action_type = 'click') as clicks,
                COUNTIF(i.action_type = 'inquiry') as inquiries,
                COUNTIF(i.action_type = 'purchase') as purchases
            FROM `{project_id}.artisan_analytics.products` p
            LEFT JOIN `{project_id}.artisan_analytics.user_interactions` i
                ON p.product_id = i.product_id
            WHERE p.artisan_id = @artisan_id
                AND i.timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)
            GROUP BY price_band
        )
        SELECT 
            price_band,
            unique_viewers,
            clicks,
            inquiries,
            purchases,
            ROUND(clicks / NULLIF(unique_viewers, 0) * 100, 2) as click_rate,
            ROUND(purchases / NULLIF(clicks, 0) * 100, 2) as conversion_rate
        FROM price_analysis
        ORDER BY clicks DESC
        """
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("artisan_id", "STRING", artisan_id)
            ]
        )
        
        results = client.query(query, job_config=job_config).result()
        
        price_bands = []
        total_clicks = 0
        
        for row in results:
            price_bands.append({
                "range": row.price_band,
                "clicks": row.clicks,
                "conversion_rate": row.conversion_rate or 0
            })
            total_clicks += row.clicks
        
        # Calculate percentages
        for band in price_bands:
            band["percentage"] = round((band["clicks"] / total_clicks * 100), 0) if total_clicks > 0 else 0
        
        return {
            "price_bands": price_bands if price_bands else get_mock_data()["price_data"]["price_bands"]
        }
        
    except Exception as e:
        print(f"Error in get_price_performance: {e}")
        return get_mock_data()["price_data"]

def get_key_insights(artisan_id: str) -> List[Dict[str, str]]:
    """Generate key actionable insights"""
    
    client = get_bigquery_client()
    
    if not client:
        print(f"Using mock data for key_insights (artisan: {artisan_id})")
        return get_mock_data()["key_insights"]
    
    try:
        project_id = os.environ.get("GCLOUD_PROJECT")
        
        query = f"""
        WITH recent_metrics AS (
            SELECT 
                COUNT(DISTINCT CASE WHEN timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY) 
                    THEN user_id END) as recent_users,
                COUNT(DISTINCT CASE WHEN timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 14 DAY) 
                    AND timestamp < TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
                    THEN user_id END) as previous_users,
                COUNTIF(timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY) 
                    AND action_type = 'inquiry') as recent_inquiries,
                COUNTIF(timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 14 DAY) 
                    AND timestamp < TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
                    AND action_type = 'inquiry') as previous_inquiries
            FROM `{project_id}.artisan_analytics.user_interactions`
            WHERE artisan_id = @artisan_id
        )
        SELECT 
            recent_users,
            previous_users,
            recent_inquiries,
            previous_inquiries,
            ROUND((recent_users - previous_users) / NULLIF(previous_users, 0) * 100, 0) as user_growth,
            ROUND((recent_inquiries - previous_inquiries) / NULLIF(previous_inquiries, 0) * 100, 0) as inquiry_growth
        FROM recent_metrics
        """
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("artisan_id", "STRING", artisan_id)
            ]
        )
        
        results = list(client.query(query, job_config=job_config).result())
        
        insights = []
        
        if results:
            row = results[0]
            
            if row.user_growth and row.user_growth > 10:
                insights.append({
                    "icon": "üìà",
                    "text": f"Your reach increased by {int(row.user_growth)}% this week",
                    "trend": "up"
                })
            
            if row.inquiry_growth and row.inquiry_growth > 15:
                insights.append({
                    "icon": "üéâ",
                    "text": f"Inquiries up {int(row.inquiry_growth)}% - customers are engaging more",
                    "trend": "up"
                })
        
        # Add default insights if not enough data
        if len(insights) < 3:
            insights.extend([
                {"icon": "‚≠ê", "text": "Products with detailed descriptions get 35% more clicks", "trend": "neutral"},
                {"icon": "üì∏", "text": "Adding 3+ images increases conversion by 25%", "trend": "neutral"}
            ])
        
        return insights[:3]
        
    except Exception as e:
        print(f"Error in get_key_insights: {e}")
        return get_mock_data()["key_insights"]

def get_recommended_channels(artisan_id: str) -> List[Dict[str, str]]:
    """Recommend marketing channels based on craft type and audience"""
    
    client = get_bigquery_client()
    
    if not client:
        print(f"Using mock data for recommended_channels (artisan: {artisan_id})")
        return get_mock_data()["recommended_channels"]
    
    try:
        project_id = os.environ.get("GCLOUD_PROJECT")
        
        query = f"""
        SELECT 
            p.craft_type,
            COUNT(DISTINCT i.user_id) as total_users,
            AVG(EXTRACT(YEAR FROM CURRENT_TIMESTAMP()) - 
                SAFE_CAST(SPLIT(d.age_group, '-')[OFFSET(0)] AS INT64)) as avg_age
        FROM `{project_id}.artisan_analytics.products` p
        LEFT JOIN `{project_id}.artisan_analytics.user_interactions` i
            ON p.product_id = i.product_id
        LEFT JOIN `{project_id}.artisan_analytics.user_demographics` d
            ON i.user_id = d.user_id
        WHERE p.artisan_id = @artisan_id
        GROUP BY p.craft_type
        LIMIT 1
        """
        
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("artisan_id", "STRING", artisan_id)
            ]
        )
        
        results = list(client.query(query, job_config=job_config).result())
        
        # Default recommendations
        channels = get_mock_data()["recommended_channels"]
        
        # Customize based on data
        if results and results[0].craft_type:
            craft = results[0].craft_type
            if craft in ['handloom', 'embroidery']:
                channels[0]["reason"] = f"Perfect for showcasing {craft} craftsmanship"
        
        return channels
        
    except Exception as e:
        print(f"Error in get_recommended_channels: {e}")
        return get_mock_data()["recommended_channels"]

def get_all_insights(artisan_id: str) -> Dict[str, Any]:
    """Get all analytics insights for an artisan"""
    
    try:
        return {
            "target_audience_data": get_target_audience(artisan_id),
            "timing_data": get_best_timing(artisan_id),
            "price_data": get_price_performance(artisan_id),
            "key_insights": get_key_insights(artisan_id),
            "recommended_channels": get_recommended_channels(artisan_id)
        }
    except Exception as e:
        print(f"‚ùå Error fetching insights for {artisan_id}: {e}")
        # Return mock data as complete fallback
        return get_mock_data()